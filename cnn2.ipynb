{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "940b1f45",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Klasyfikacja-obrazów-za-pomocą-CNN\" data-toc-modified-id=\"Klasyfikacja-obrazów-za-pomocą-CNN-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Klasyfikacja obrazów za pomocą CNN</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dane:-psy-i-koty\" data-toc-modified-id=\"Dane:-psy-i-koty-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Dane: psy i koty</a></span></li><li><span><a href=\"#Wczytywanie-danych:-ImageDataGenerator\" data-toc-modified-id=\"Wczytywanie-danych:-ImageDataGenerator-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Wczytywanie danych: ImageDataGenerator</a></span></li><li><span><a href=\"#Przykładowa-próbka-generatora-danych\" data-toc-modified-id=\"Przykładowa-próbka-generatora-danych-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Przykładowa próbka generatora danych</a></span></li><li><span><a href=\"#Model-CNN-klasyfikacji\" data-toc-modified-id=\"Model-CNN-klasyfikacji-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Model CNN klasyfikacji</a></span></li><li><span><a href=\"#Trening-sieci\" data-toc-modified-id=\"Trening-sieci-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Trening sieci</a></span></li><li><span><a href=\"#Wizualizacja-aktywacji-map-cech\" data-toc-modified-id=\"Wizualizacja-aktywacji-map-cech-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Wizualizacja aktywacji map cech</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ćwiczenie:-warstwa-Dropout\" data-toc-modified-id=\"Ćwiczenie:-warstwa-Dropout-1.6.1\"><span class=\"toc-item-num\">1.6.1&nbsp;&nbsp;</span>Ćwiczenie: warstwa Dropout</a></span></li></ul></li><li><span><a href=\"#Data-augmentation\" data-toc-modified-id=\"Data-augmentation-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Data augmentation</a></span></li><li><span><a href=\"#Przykład-transfromacji\" data-toc-modified-id=\"Przykład-transfromacji-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Przykład transfromacji</a></span></li><li><span><a href=\"#Rozszerzony-zbiór-uczący\" data-toc-modified-id=\"Rozszerzony-zbiór-uczący-1.9\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>Rozszerzony zbiór uczący</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ćwiczenie\" data-toc-modified-id=\"Ćwiczenie-1.9.1\"><span class=\"toc-item-num\">1.9.1&nbsp;&nbsp;</span>Ćwiczenie</a></span></li></ul></li><li><span><a href=\"#Zapis-modelu\" data-toc-modified-id=\"Zapis-modelu-1.10\"><span class=\"toc-item-num\">1.10&nbsp;&nbsp;</span>Zapis modelu</a></span></li><li><span><a href=\"#Wytrenowane-modele-Keras\" data-toc-modified-id=\"Wytrenowane-modele-Keras-1.11\"><span class=\"toc-item-num\">1.11&nbsp;&nbsp;</span>Wytrenowane modele Keras</a></span></li><li><span><a href=\"#InceptionV3\" data-toc-modified-id=\"InceptionV3-1.12\"><span class=\"toc-item-num\">1.12&nbsp;&nbsp;</span>InceptionV3</a></span></li><li><span><a href=\"#Klasyfikacja-obrazu-za-pomocą-InceptionV3\" data-toc-modified-id=\"Klasyfikacja-obrazu-za-pomocą-InceptionV3-1.13\"><span class=\"toc-item-num\">1.13&nbsp;&nbsp;</span>Klasyfikacja obrazu za pomocą InceptionV3</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ćwiczenie\" data-toc-modified-id=\"Ćwiczenie-1.13.1\"><span class=\"toc-item-num\">1.13.1&nbsp;&nbsp;</span>Ćwiczenie</a></span></li></ul></li><li><span><a href=\"#Transfer-learning\" data-toc-modified-id=\"Transfer-learning-1.14\"><span class=\"toc-item-num\">1.14&nbsp;&nbsp;</span>Transfer learning</a></span></li><li><span><a href=\"#Zamrożenie-wag\" data-toc-modified-id=\"Zamrożenie-wag-1.15\"><span class=\"toc-item-num\">1.15&nbsp;&nbsp;</span>Zamrożenie wag</a></span></li><li><span><a href=\"#Wybór-warstwy-do-ekstrakcji-cech\" data-toc-modified-id=\"Wybór-warstwy-do-ekstrakcji-cech-1.16\"><span class=\"toc-item-num\">1.16&nbsp;&nbsp;</span>Wybór warstwy do ekstrakcji cech</a></span></li><li><span><a href=\"#Nowa-warstwa-ucząca-i-klasyfikująca\" data-toc-modified-id=\"Nowa-warstwa-ucząca-i-klasyfikująca-1.17\"><span class=\"toc-item-num\">1.17&nbsp;&nbsp;</span>Nowa warstwa ucząca i klasyfikująca</a></span></li><li><span><a href=\"#Douczanie-(fine-tuning)\" data-toc-modified-id=\"Douczanie-(fine-tuning)-1.18\"><span class=\"toc-item-num\">1.18&nbsp;&nbsp;</span>Douczanie (fine tuning)</a></span></li><li><span><a href=\"#Zadanie\" data-toc-modified-id=\"Zadanie-1.19\"><span class=\"toc-item-num\">1.19&nbsp;&nbsp;</span>Zadanie</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51109d24-180e-448f-95fc-b36e429e3c8a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Klasyfikacja obrazów za pomocą CNN\n",
    "\n",
    "\n",
    "* rozszerzanie danych (*data augmentation*)\n",
    "* korzytsanie z wytrenowanych modeli (*model zoo*)\n",
    "* ekstrakcja cech z wytrenowanych modeli (*transfer learning*)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554db476-a003-4a45-9f37-8f0aa519a1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8869d3ba-cf4f-4c1d-8c53-216b9120852b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dane: psy i koty\n",
    "\n",
    "\n",
    "Zredukowany do 3000 przypadków zbiór danych klasyfikacji psþw i kotów. \n",
    "\n",
    "Pobierz dane z adresu https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
    "i rozpakuj w bieżacej lokalizacji. \n",
    "\n",
    "Wybrane 3000 obrazów (trening po 1000 psów i 1000 kotów, walidacja po 500 psów i 500 kotów)\n",
    "```\n",
    "cats_and_dogs_filtered/\n",
    "    train/\n",
    "        dogs/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "    validation/\n",
    "        dogs/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc6d99-e321-4a3a-aae8-bd53827a9902",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './dane/cats_and_dogs_filtered'\n",
    "train_dir = base_dir + '/train'\n",
    "validation_dir = base_dir + '/validation'\n",
    "\n",
    "print('total training cat images:', len(os.listdir(train_dir + '/cats')))\n",
    "print('total training dog images:', len(os.listdir(train_dir + '/dogs')))\n",
    "print('total validation cat images:', len(os.listdir(validation_dir + '/cats')))\n",
    "print('total validation dog images:', len(os.listdir(validation_dir + '/dogs')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7942a848",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wyświetlmy kilka przykładowych obrazów z obu klas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e482e654-27a7-4a9a-9358-6358e938f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_img = 4\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(16, 8))\n",
    "for i, label in enumerate(['cats', 'dogs']):\n",
    "    files = os.listdir(train_dir + '/' + label)\n",
    "    for j, fname in enumerate(np.random.permutation(files)[:n_img]):\n",
    "        img = plt.imread(os.path.join(train_dir, label, fname))\n",
    "        axs[i, j].imshow(img)\n",
    "        axs[i, j].set_title(fname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf653711-dba6-47b1-8cd0-12a04b9a4314",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Wczytywanie danych: ImageDataGenerator\n",
    "\n",
    "\n",
    "* [tf.keras.preprocessing.image.ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) <br> Klasa do generowania sekwencji obrazów wraz z automatycznymi transformacjami (rozszerzanie danych). <br> np. argument ``rescale`` przemnaża przez podaną wartość\n",
    "* metoda [flow_from_directory()](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory) <br> zwraca iterator grenerujący paczki danych\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6046875-6f72-45a0-86cb-30fa295e2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "target_size=(150, 150)\n",
    "batch_size=64\n",
    "class_mode='binary'  # klasyfikacja 2 klas\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=target_size, \n",
    "                                                    batch_size=batch_size, class_mode=class_mode)\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(validation_dir, target_size=target_size, \n",
    "                                                       batch_size=batch_size, class_mode=class_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59439c46",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Przykładowa próbka generatora danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fc3808-e643-4c8d-b016-3753874b8c84",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X, t = train_generator.next()\n",
    "print('Wymiary X', X.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(X[0, :, :, :])\n",
    "plt.title('Klasa %.0f' % t[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc0f7d5-1224-4f6d-9a8e-aa1efd8024d0",
   "metadata": {},
   "source": [
    "## Model CNN klasyfikacji\n",
    "\n",
    "Zbudujmy model CNN składający się z typowych elementów \n",
    "\n",
    "* warstwa wejściowa ``[150, 150, 3]``\n",
    "* warstwy Conv2D, MaxPool, \n",
    "* warstwa wyjsciowa 1 neuron ``sigmoid``, klasyfikacja binarna etykiety 0 lub 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67ccf7e-1c96-4436-ba08-3fecf0830cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inputs = layers.Input(shape=(150, 150, 3))\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu')(inputs)\n",
    "x = layers.MaxPool2D(2)(x)\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPool2D(2)(x)\n",
    "\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca54986-0a4c-4da5-b7a5-c1e06a006cb3",
   "metadata": {},
   "source": [
    "## Trening sieci \n",
    "\n",
    "Konfiguracja treningu:\n",
    "* funkcja kosztu ``binary_crossentropy`` do klasyfikacji binarnej\n",
    "* metryka ``binary_accuracy`` - miara poprawności klasyfikacji binarnej\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f86b6-fb28-4a70-9877-aeb0e9a67b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(learning_rate=0.001),\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "model.fit(train_generator, epochs=15, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbe669b-3409-4396-9127-18120e0f766f",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "history = model.history.history\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].plot(history['loss'], '-r', label=\"Training\")\n",
    "ax[0].plot(history['val_loss'], '-b', label=\"Validation\")\n",
    "ax[0].set_xlabel('Epoch #')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(history['binary_accuracy'], '-r', label=\"Training\")\n",
    "ax[1].plot(history['val_binary_accuracy'], '-b', label=\"Validation\")\n",
    "ax[1].set_xlabel('Epoch #')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3295af32",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Wizualizacja aktywacji map cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12021f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# wybrane warstwy splotowe \n",
    "layers = [ model.layers[1].output, model.layers[3].output ]\n",
    "layer_names = [layer.name for layer in layers]\n",
    "\n",
    "vis_model = Model(model.inputs, layers)\n",
    "\n",
    "img = load_img('dane/cats_and_dogs_filtered/train/cats/cat.1.jpg', target_size=(150, 150))  \n",
    "\n",
    "x = img_to_array(img)  \n",
    "x = x.reshape((1,) + x.shape) / 255.0  \n",
    "\n",
    "feature_maps = vis_model.predict(x)\n",
    "\n",
    "for layer_name, feature_map in zip(layer_names, feature_maps):\n",
    "    n_features = feature_map.shape[-1] \n",
    "    \n",
    "    # The feature map has shape (1, size, size, n_features)\n",
    "    size = feature_map.shape[1]\n",
    "    display_grid = np.zeros((size, size * n_features))\n",
    "    for i in range(n_features):\n",
    "        x = feature_map[0, :, :, i] \n",
    "        x = x / x.max() \n",
    "        display_grid[:, i * size : (i + 1) * size] = x\n",
    "    \n",
    "    # Display the grid\n",
    "    scale = 20. / n_features\n",
    "    plt.figure(figsize=(scale * n_features, scale))\n",
    "    plt.title(layer_name)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d047f72",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ćwiczenie: warstwa Dropout\n",
    "\n",
    "Dodaj warstwę dropout na wyjsciu warstw splotowych i gęstych aby ograniczyć preuczenie.   \n",
    "Wytrenuj model i porównaj uzyskany wynik z poprzednią architektura bez warstwy dropout.  \n",
    "Zobacz jaki wpływ na wynik ma wartość argumentu ``rate``.\n",
    "\n",
    "Dokumentacja: [tf.keras.layers.Dropout(rate)](https://keras.io/api/layers/regularization_layers/dropout/)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2c69e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7d060f-ec03-4175-803c-6beb2a9aa96e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data augmentation\n",
    "\n",
    "Dodajmy losowe transformacje obrazów, które spowodują sztuczen zwielokrotnienie zbioru uczacego - w praktyce żaden obraz wejściowy nie będzie się powtarzał.  \n",
    "\n",
    "Zapoznaj się z argumentami konstruktora [tf.keras.preprocessing.image.ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f46c8b-e427-492f-bc5c-b87542821fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,           # obrót w stopniach 0-180\n",
    "    width_shift_range=0.2,       # przesunięcie poziome (o 0.2 szerokości)\n",
    "    height_shift_range=0.2,      # przesuniecie pionowe\n",
    "    shear_range=0.2,             # ścinanie\n",
    "    zoom_range=0.2,              # powiększanie\n",
    "    horizontal_flip=True,        # odwracanie\n",
    "    fill_mode='nearest'          # wypełnianie brakujacych pikseli powstających po transfromacjach\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b925396",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Przykład transfromacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2720a3-55fa-4cf7-8608-967cf6e5ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread('dane/cats_and_dogs_filtered/train/cats/cat.1.jpg')\n",
    "img = img.reshape((1,) + img.shape)\n",
    "generator = datagen.flow(img, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66f2e45-5665-48e7-866e-ad72a592cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented = generator.next()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 8))\n",
    "ax[0].imshow(img[0, :, :, :]/255.)\n",
    "ax[0].set_title(\"Original\")\n",
    "ax[1].imshow(augmented[0, :, :, :])\n",
    "ax[1].set_title(\"Augmented\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a1c35-89bb-49c5-b504-31aa09094b72",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Rozszerzony zbiór uczący\n",
    "\n",
    "* zbiór uczący jest rozszerzony o losowe transformacje\n",
    "* generator zbioru walidacyjnego pozostaje bez zmian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162f3010-a728-4bf2-b3fc-a18e91d13561",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "augmented_train_generator = augmented_train_datagen.flow_from_directory(\n",
    "        train_dir, \n",
    "        target_size=(150, 150),  \n",
    "        batch_size=64,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e544df52",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ćwiczenie\n",
    "\n",
    "Zbuduj ponowanie poprzednio uzywany model z warstwami dropout uzywając rozszerzonego zbioru treningowego i porównaj wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6d4509-0250-47f9-b8ce-602133965ed3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d43689c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zapis modelu \n",
    "\n",
    "* zapis model metoda [save()](https://keras.io/api/saving/model_saving_and_loading/#save-method) \n",
    "* odczyt modelu [tf.keras.models.load_model()](https://keras.io/api/saving/model_saving_and_loading/#loadmodel-function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e062b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zapis do formatu pliku HDF5 \n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3da51e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 =  tf.keras.models.load_model(\"model.h5\")\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3b921c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Wytrenowane modele Keras \n",
    "\n",
    "Modele dostepne w Keras https://keras.io/api/applications/\n",
    "\n",
    "* VGG16, VGG19\n",
    "* ResNet50, ResNet101\n",
    "* InceptionV3, Xception\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d8ea27-ac1c-4ea1-a9e4-c98e1b2e4d61",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## InceptionV3\n",
    "\n",
    "Model [InceptionV3](https://keras.io/api/applications/inceptionv3/) wytrenowany na zbiorze ImageNet 1.4M obrazów podzielonych na 1000 klas.\n",
    "\n",
    "Uwaga: przy pierwszym uruchomieniu model jest pobierany (pod Linuxem do ``~/.keras/models/``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2eb247-3b38-4705-9e96-837841e02f60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "model = InceptionV3(weights='imagenet')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f81a46-aedd-4614-bdcc-496a6113276c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Klasyfikacja obrazu za pomocą InceptionV3\n",
    "\n",
    "\n",
    "Przygotowanie obrazu do wejścia sieci [tf.keras.applications.inception_v3.preprocess_input()](https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/preprocess_input)  - każda wytrenowana sieć może wymagać specyficznej transformacji. \n",
    "Odkodowanie etykiet klas ImageNet z wyjścia sieci [tf.keras.applications.inception_v3.decode_predictions()](https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/decode_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cd3417-be29-4f36-ba7d-cbec1736fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import pandas as pd\n",
    "\n",
    "model = InceptionV3(weights='imagenet')\n",
    "\n",
    "img_path = 'dane/cats_and_dogs_filtered/train/cats/cat.1.jpg'\n",
    "\n",
    "img = image.load_img(img_path, target_size=(299, 299))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = tf.keras.applications.inception_v3.preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "\n",
    "decoded = tf.keras.applications.inception_v3.decode_predictions(preds, top=5)[0]\n",
    "print('Predicted:', decoded)\n",
    "dt = pd.DataFrame(decoded, columns=['Name', 'Label', 'Prob'])\n",
    "dt.plot.barh(x='Label', y='Prob');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661fb6ea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ćwiczenie\n",
    "\n",
    "Użyj sieci InceptionV3 do predykcji obiektu na dowolnym zdjęciu np. pobranym z internetu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686101cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d764ca30-0ed0-4fff-a913-94eb538cfd96",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Transfer learning\n",
    "\n",
    "Exstrakcja cech z wytrenowanych modeli i douczanie na nowym problemie\n",
    "* usuwamy warstwę klasyfikujacą modelu wytrenowanego na duzym zbiorze danych\n",
    "* zamrażamy wagi (ustawiamy ``trainable=False``) aby nie były optylizowane w czasie douczania\n",
    "* dodajemy własne warstwy oraz warstwę klasyfikującą\n",
    "* uczymy na nowych danych \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472c1cc9-2f01-4e54-a97c-1e9827bc55bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "pre_trained_model = InceptionV3(\n",
    "        weights=\"imagenet\",  \n",
    "        include_top=False,           # pobiera model z usunietą ostatnią warstwą\n",
    "        input_shape=(150, 150, 3),   # dla sieci w roli ekstraktora cech mozemy ustalic rowmiar wejscia\n",
    "    )\n",
    "\n",
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c84e59c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zamrożenie wag\n",
    "\n",
    "Dowolne warstwy mogą być wyłączone z procesu uczenia (sygnał będzie nadal przez nie przetwarzany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cecadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pre_trained_model.layers:\n",
    "      layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e314cf",
   "metadata": {},
   "source": [
    "To samo można wykonac dla całej sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafa2f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model.trainable = False\n",
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7497df69",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Wybór warstwy do ekstrakcji cech\n",
    "\n",
    "* najczęściej wybiera się ostatnią warstwę ale możemy wybrać inną, wcześniejszą"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d156b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed10')\n",
    "\n",
    "print('last layer output shape:', last_layer.output_shape)\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60072e4b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nowa warstwa ucząca i klasyfikująca\n",
    "\n",
    "* wypłaszczenie mapy cech ``Flatten()``, gdy mapa jest kwadratowa to można użyć w tym celu warstwy ``GlobalAveragePooling2D()``\n",
    "* dodanie warstw gęstych oraz warstwy klasyfikującej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b60be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Flatten()(last_output)\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(pre_trained_model.input, x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1750ca80",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Douczanie (fine tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ca0773-bd59-4405-b1ce-4d149da10da8",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "      augmented_train_generator,\n",
    "      epochs=2,\n",
    "      validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741927a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zadanie\n",
    "\n",
    "Zbuduj jak najlepszy model klasyfikacji dla zbioru danych kotów i psów wykorzystując transfer learning oraz rozszerzanie danych:\n",
    "*  w roli ekstraktora cech wybierz dowolny model wytrenowany na danych ImageNet. <br> Lista modeli dotępnych w Keras znajduje się tu [Model ZOO](https://keras.io/api/applications/). \n",
    "* na wyjściu ekstraktora cech dodaj jedną warstę w pełni połączoną (gęstą) zawierającą minimum 200 jednostek `relu` oraz warstwę regularyzacyjną Dropout a następnie wyjście sieci z jednym neuronem i funkcją aktywacji ``sigmoid`` (klasyfikacja binarna).\n",
    "* przeprowadź preces douczania trwający conajmniej 10 epok z wykorzystaniem rozszerzania zbioru danych poprzez automatyczne generowane transroamacje obrazu\n",
    "* wyrysuj przebieg funkcij kosztu oraz poprawności klasyfikacji na zbiorze treningowym i walidacyjnym "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b07bbaf-f3ca-428d-8a02-739ed5db9f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
